{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "7e1d7ef97767342f76cd68dd7fe371509249fe149e1988b82e6373875a9df1cb"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "convolutional.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxvmRwAwPND_"
      },
      "source": [
        "# importing the keras librareis and packages\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp3Y1ARTPNEE",
        "outputId": "9594f69f-48af-42b2-ffd9-dec1b39f139b"
      },
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio(\"featured\", output=\"dataset\", seed=1337, ratio=(.8, .1, .1), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 792 files [00:02, 353.54 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZlbz9VPNEG",
        "outputId": "89282f70-f891-474e-b846-0269da8d845d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/identity/dataset/train',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=630,\n",
        "    class_mode='binary')\n",
        "\n",
        "val_set = val_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/identity/dataset/val',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=87,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 630 images belonging to 10 classes.\n",
            "Found 75 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FcMBZ8cPoby",
        "outputId": "50d9fe0a-6da4-4c18-e9c9-30b7c4ae8d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqZJSrjDPNEH",
        "outputId": "b7846dd7-72bf-4502-c49a-f43375f36ca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model = Xception(weights=\"imagenet\", include_top=False)\n",
        "avg = GlobalAveragePooling2D()(base_model.output)\n",
        "output = Dense(1, activation=\"softmax\")(avg)\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "83697664/83683744 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCF5fNSrPNEH"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "optimizer = SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "training = model.fit(training_set, validation_data=val_set, epochs=3)\n",
        "model.save('model')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}